{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import pickle\n",
    "import scipy\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "def extract_segment_with_padding(z, k, N):\n",
    "    start_idx = k - N\n",
    "    end_idx = k + N + 1\n",
    "    if start_idx < 0:\n",
    "        padding_left = np.median(z[:end_idx])\n",
    "        segment = np.concatenate([np.full(-start_idx, padding_left), z[:end_idx]])\n",
    "    elif end_idx > len(z):\n",
    "        padding_right = np.median(z[start_idx:])\n",
    "        segment = np.concatenate([z[start_idx:], np.full(end_idx - len(z), padding_right)])\n",
    "    else:\n",
    "        segment = z[start_idx:end_idx]\n",
    "    return segment\n",
    "\n",
    "class MIT_BIH_Arythmia(Dataset):\n",
    "    def __init__(self, N, M, dataset_dir='Datasets/files/', fs=10, output_dir=\"processed_data/\", histogram_path=None):\n",
    "        self.N = N\n",
    "        self.M = M\n",
    "        if histogram_path and os.path.exists(histogram_path):\n",
    "            with open(histogram_path, 'rb') as f:\n",
    "                self.cumulative_histogram = pickle.load(f)\n",
    "            print(\"Załadowano histogram:\", histogram_path)\n",
    "        else:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            exclusion_lst = [str(i) for i in range(10, 11)]\n",
    "            self.cumulative_histogram = []\n",
    "            start_idx = 0\n",
    "            for file in os.listdir(dataset_dir):\n",
    "                name = re.match(r'^(.*\\d\\d+)\\.atr$', file)\n",
    "                if name and name.group(1) not in exclusion_lst:\n",
    "                    print(f\"Przetwarzanie: {name.group(1)}\")\n",
    "                    record = wfdb.rdsamp(f\"{dataset_dir}{name.group(1)}\")\n",
    "                    annotation = wfdb.rdann(f\"{dataset_dir}{name.group(1)}\", 'atr')\n",
    "                    signal = record[0][:, 0]\n",
    "                    fs_original = record[1][\"fs\"]\n",
    "                    num_samples_target = int(signal.shape[0] * fs / fs_original)\n",
    "                    resampled_signal = scipy.signal.resample(signal, num_samples_target)\n",
    "                    annotation_times_resampled = (annotation.sample * fs) / fs_original\n",
    "                    data = {\n",
    "                        \"rec\": resampled_signal,\n",
    "                        \"ann\": {\n",
    "                            \"sample\": annotation_times_resampled.astype(int).tolist(),\n",
    "                            \"aux_note\": annotation.aux_note\n",
    "                        }\n",
    "                    }\n",
    "                    output_filename = os.path.join(output_dir, f\"{name.group(1)}.pkl\")\n",
    "                    with open(output_filename, 'wb') as f:\n",
    "                        pickle.dump(data, f)\n",
    "                    num_samples = len(data[\"ann\"][\"sample\"])\n",
    "                    self.cumulative_histogram.append((start_idx, start_idx + num_samples, output_filename))\n",
    "                    start_idx += num_samples\n",
    "            histogram_path = os.path.join(output_dir, \"cumulative_histogram.pkl\")\n",
    "            with open(histogram_path, 'wb') as f:\n",
    "                pickle.dump(self.cumulative_histogram, f)\n",
    "            print(\"Przetwarzanie zakończone. Dane zapisane w:\", output_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.cumulative_histogram[-1][1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "    # Przejdź przez histogram skumulowany, aby znaleźć odpowiedni plik i zakres indeksów\n",
    "        for start, end, filename in self.cumulative_histogram:\n",
    "            if start <= idx < end:\n",
    "                local_idx = idx - start  # Oblicz indeks lokalny w danym pliku\n",
    "                break\n",
    "        else:\n",
    "            raise IndexError(\"Index out of range\")  # Jeśli nie znajdziesz odpowiedniego zakresu, zgłoś błąd\n",
    "        \n",
    "        # Załaduj dane z odpowiedniego pliku\n",
    "        with open(filename, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Pobierz sygnał EKG i informacje o annotacjach\n",
    "        rec = data[\"rec\"]\n",
    "        sample_idx = data[\"ann\"][\"sample\"][local_idx]  # Indeks próbki w danym pliku\n",
    "        aux_note = data[\"ann\"][\"aux_note\"][local_idx]  # Etykieta (np. AFIB lub NORMAL)\n",
    "        \n",
    "        # Wyciąć odpowiedni segment EKG wokół punktu annotacji\n",
    "        segment = extract_segment_with_padding(rec, sample_idx, self.N)\n",
    "        \n",
    "        # Ustal etykietę: 1 dla AFIB, 0 dla NORMAL\n",
    "        label = 1 if aux_note == '(AFIB' else 0\n",
    "        return torch.Tensor(segment).unsqueeze(0), label\n",
    "\n",
    "    def count_afibs(self):\n",
    "        afib_count = 0\n",
    "        for start, end, filename in self.cumulative_histogram:\n",
    "            # Załaduj dane z pliku\n",
    "            with open(filename, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            \n",
    "            # Sprawdź wszystkie etykiety i policz AFIB\n",
    "            for aux_note in data[\"ann\"][\"aux_note\"]:\n",
    "                if \"(AFIB\" in aux_note:\n",
    "                    afib_count += 1\n",
    "        return afib_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przetwarzanie: 00\n",
      "Przetwarzanie: 01\n",
      "Przetwarzanie: 03\n",
      "Przetwarzanie: 05\n",
      "Przetwarzanie: 06\n",
      "Przetwarzanie: 07\n",
      "Przetwarzanie: 08\n",
      "Przetwarzanie: 100\n",
      "Przetwarzanie: 101\n",
      "Przetwarzanie: 102\n",
      "Przetwarzanie: 103\n",
      "Przetwarzanie: 104\n",
      "Przetwarzanie: 105\n",
      "Przetwarzanie: 11\n",
      "Przetwarzanie: 110\n",
      "Przetwarzanie: 111\n",
      "Przetwarzanie: 112\n",
      "Przetwarzanie: 113\n",
      "Przetwarzanie: 114\n",
      "Przetwarzanie: 115\n",
      "Przetwarzanie: 116\n",
      "Przetwarzanie: 117\n",
      "Przetwarzanie: 118\n",
      "Przetwarzanie: 119\n",
      "Przetwarzanie: 12\n",
      "Przetwarzanie: 120\n",
      "Przetwarzanie: 121\n",
      "Przetwarzanie: 122\n",
      "Przetwarzanie: 13\n",
      "Przetwarzanie: 15\n",
      "Przetwarzanie: 16\n",
      "Przetwarzanie: 17\n",
      "Przetwarzanie: 18\n",
      "Przetwarzanie: 19\n",
      "Przetwarzanie: 20\n",
      "Przetwarzanie: 200\n",
      "Przetwarzanie: 201\n",
      "Przetwarzanie: 202\n",
      "Przetwarzanie: 203\n",
      "Przetwarzanie: 204\n",
      "Przetwarzanie: 205\n",
      "Przetwarzanie: 206\n",
      "Przetwarzanie: 207\n",
      "Przetwarzanie: 208\n",
      "Przetwarzanie: 21\n",
      "Przetwarzanie: 22\n",
      "Przetwarzanie: 23\n",
      "Przetwarzanie: 24\n",
      "Przetwarzanie: 25\n",
      "Przetwarzanie: 26\n",
      "Przetwarzanie: 28\n",
      "Przetwarzanie: 30\n",
      "Przetwarzanie: 32\n",
      "Przetwarzanie: 33\n",
      "Przetwarzanie: 34\n",
      "Przetwarzanie: 35\n",
      "Przetwarzanie: 37\n",
      "Przetwarzanie: 38\n",
      "Przetwarzanie: 39\n",
      "Przetwarzanie: 42\n",
      "Przetwarzanie: 43\n",
      "Przetwarzanie: 44\n",
      "Przetwarzanie: 45\n",
      "Przetwarzanie: 47\n",
      "Przetwarzanie: 48\n",
      "Przetwarzanie: 49\n",
      "Przetwarzanie: 51\n",
      "Przetwarzanie: 53\n",
      "Przetwarzanie: 54\n",
      "Przetwarzanie: 55\n",
      "Przetwarzanie: 56\n",
      "Przetwarzanie: 58\n",
      "Przetwarzanie: 60\n",
      "Przetwarzanie: 62\n",
      "Przetwarzanie: 64\n",
      "Przetwarzanie: 65\n",
      "Przetwarzanie: 68\n",
      "Przetwarzanie: 69\n",
      "Przetwarzanie: 70\n",
      "Przetwarzanie: 71\n",
      "Przetwarzanie: 72\n",
      "Przetwarzanie: 74\n",
      "Przetwarzanie: 75\n",
      "Przetwarzanie zakończone. Dane zapisane w: processed_data/\n"
     ]
    }
   ],
   "source": [
    "ds = MIT_BIH_Arythmia(100,5,fs=100,dataset_dir='Datasets/temp/physionet.org/files/ltafdb/1.0.0/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import re\n",
    "import wfdb\n",
    "import wfdb.processing\n",
    "import scipy\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv(nn.Module):\n",
    "    def __init__(self, input = 201, input_ch = 1, num_classes = 2):\n",
    "        super(SimpleConv, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(input_ch, 64, kernel_size=7, padding='same'),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=3, padding='same'),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding='same'),      # out 1 x 128 x n\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),                        # out 1 x 128 x n//2\n",
    "            nn.Conv1d(128, 128, kernel_size=3, padding='same'),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding='same'),     # out 1 x 256 x n//2\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),                        # out 1 x 256 x n//4\n",
    "            nn.Conv1d(256, 256, kernel_size=3, padding='same'),     \n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 512, kernel_size=3, padding='same'),     \n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),                        # out 1 x 512 x n//8\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512*(input//8), 256),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "        self.model.to('cuda:0')\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.model(x)\n",
    "    \n",
    "    def train_model(self, train_loader, valid_loader, num_epochs = 5, learning_rate=0.001, save_best = False, save_thr = 0.94):\n",
    "        best_accuracy = 0.0\n",
    "        total_step = len(train_loader)\n",
    "        # Loss and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.RMSprop(self.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # self.train()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for i, (images, labels) in enumerate(tqdm(train_loader)):\n",
    "                # Move tensors to the configured device\n",
    "                images = images.float().to(\"cuda\")\n",
    "                labels = labels.type(torch.LongTensor)\n",
    "                labels = labels.to(\"cuda\")\n",
    "\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = self.forward(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                # Backward and optimize\n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "\n",
    "                # accuracy\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                correct += (torch.eq(predicted, labels)).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "                del images, labels, outputs\n",
    "\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.4f}'\n",
    "                            .format(epoch+1, num_epochs, i+1, total_step, loss.item(), (float(correct))/total))\n",
    "\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            # Validation\n",
    "            with torch.no_grad():\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for images, labels in valid_loader:\n",
    "                    images = images.float().to(\"cuda\")\n",
    "                    labels = labels.to(\"cuda\")\n",
    "                    outputs = self.forward(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (torch.eq(predicted, labels)).sum().item()\n",
    "                    del images, labels, outputs\n",
    "                if(((100 * correct / total) > best_accuracy) and save_best and ((100 * correct / total) > save_thr)):\n",
    "                    torch.save(self.state_dict(), \"best_resnet50_MINST-DVS2.pt\")\n",
    "\n",
    "                print('Accuracy of the network: {} %'.format( 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleConv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "train_set, val_set = random_split(ds, [0.8, 0.2])\n",
    "train = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=4)\n",
    "val = DataLoader(val_set, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/223721 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model.train_model(train,val,num_epochs=90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
